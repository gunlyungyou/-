{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjsfu\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from konlpy.utils import pprint\n",
    "import time\n",
    "from konlpy.tag import Kkma, Twitter, Komoran\n",
    "import csv\n",
    "from scipy import spatial\n",
    "import pyemd\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import quandl\n",
    "import pickle\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "#정규식\n",
    "import re\n",
    "\n",
    "# random\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label과 data 읽기\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#문서의 data를 quarter별로 저장하기\n",
    "name = ['현대차', '현대중공업', '한국전력', 'LG디스플레이']\n",
    "year = ['2008','2009','2010','2011','2012','2013','2014','2015','2016','2017']\n",
    "quarter = ['1분기', '2분기', '3분기', '4분기']\n",
    "data = []\n",
    "for i in name:\n",
    "    for j in year:\n",
    "        for k in quarter:\n",
    "            quar_labels = []\n",
    "            quar_data = []\n",
    "            my_path = 'C:/Users/rjsfu/Dropbox/task/텍스트마이닝/data/신문기사/'+i+'/'+j+'/'+k\n",
    "            for  l in listdir(my_path):\n",
    "                if l.endswith('.txt'):\n",
    "                    quar_labels.append(l)\n",
    "            for doc in quar_labels:\n",
    "                with open(my_path+ '/' + doc, 'r', encoding = 'utf-8') as f2:\n",
    "                        document = f2.read()\n",
    "                        document = re.sub('[a-zA-Z]', '', document)\n",
    "                        document = re.sub('[【】◆•◇ⓒ○→*■ㆍ\\t\\n\\{\\}\\[\\]\\/?,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]',\n",
    "                                          '', document)\n",
    "                        quar_data.append(document)\n",
    "                        f2.close()\n",
    "            data.append(quar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분리된 token pickle 파일로 저장하기\n",
    "out_path = \"C:/Users/rjsfu/Dropbox/task/텍스트마이닝/pickle data\"\n",
    "\n",
    "out_file = out_path + \"/four_corp_data.pkl\"\n",
    "with open(out_file, 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/rjsfu/Dropbox/task/텍스트마이닝/pickle data/four_corp_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjsfu\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469.694 secs\n"
     ]
    }
   ],
   "source": [
    "#문서를 형태소 분리\n",
    "tagger = Twitter()\n",
    "tokens = []\n",
    "tag = ['Noun', 'Advjective']\n",
    "process_time= time.time()\n",
    "for quar_data in data:\n",
    "    tokens_quar = []\n",
    "    for text in quar_data:\n",
    "        article = []\n",
    "        tagged = tagger.pos(text)\n",
    "        for word, pos in tagged:\n",
    "            if pos in tag:\n",
    "                article.append(word)\n",
    "        tokens_quar.append(article)\n",
    "    tokens.append(tokens_quar)\n",
    "process_time = time.time() - process_time\n",
    "print('%.3f secs' % (process_time))\n",
    "\n",
    "#한글자 지우기\n",
    "remove_one = []\n",
    "for i in tokens:\n",
    "    quar_remove_one = []\n",
    "    for j in i:\n",
    "        article_remove_one = []\n",
    "        for k in j:\n",
    "            if len(k) == 1:\n",
    "                pass\n",
    "            else:\n",
    "                article_remove_one.append(k)\n",
    "        quar_remove_one.append(article_remove_one)\n",
    "    remove_one.append(quar_remove_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분리된 remove_one pickle 파일로 저장하기\n",
    "out_path = \"C:/Users/rjsfu/Dropbox/task/텍스트마이닝/pickle data\"\n",
    "\n",
    "out_file = out_path + \"/four_corp_remoce_one.pkl\"\n",
    "with open(out_file, 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#감성사전 불러오기\n",
    "with open('C:/Users/rjsfu/Dropbox/task/텍스트마이닝/pickle data/sentiment_dict_article.pkl', 'rb') as f:\n",
    "    sentiment_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4158"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_dict['neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기업별 분기별 데이터 나누기\n",
    "data_현대차 = remove_one[:40]\n",
    "data_현대중공업 = remove_one[40:80]\n",
    "data_한국전력 = remove_one[80:120]\n",
    "data_LG디스플레이 = remove_one[120:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#현대차 분기의 마지막 10기사의 점수\n",
    "point = []\n",
    "\n",
    "for i in data_현대차: #한개의 분기\n",
    "    quar_point = []\n",
    "    reverse = i[::-1][:9]\n",
    "    for j in reverse:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        neu = 0\n",
    "        for k in j:\n",
    "            if k in sentiment_dict['positive']:\n",
    "                pos += 1\n",
    "            elif k in sentiment_dict['negative']:\n",
    "                neg += 1\n",
    "            elif k in sentiment_dict['neutral']:\n",
    "                neu += 1\n",
    "            else:\n",
    "                 pass\n",
    "        if pos == 0 and neg == 0:\n",
    "            quar_point.append(0)\n",
    "        else:\n",
    "            art_point = (pos-neg)/(pos+neg)\n",
    "            quar_point.append(art_point)\n",
    "    point.append(quar_point)\n",
    "    \n",
    "mean_point_현대차 = []\n",
    "\n",
    "for i in point:\n",
    "    if len(i) == 0:\n",
    "        mean_point_현대차.append(0)\n",
    "    else:\n",
    "        mean_point_현대차.append(sum(i, 0.0)/len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#현대중공업 분기의 마지막 10기사의 점수\n",
    "point = []\n",
    "\n",
    "for i in data_현대중공업: #한개의 분기\n",
    "    quar_point = []\n",
    "    reverse = i[::-1][:9]\n",
    "    for j in reverse:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        neu = 0\n",
    "        for k in j:\n",
    "            if k in sentiment_dict['positive']:\n",
    "                pos += 1\n",
    "            elif k in sentiment_dict['negative']:\n",
    "                neg += 1\n",
    "            elif k in sentiment_dict['neutral']:\n",
    "                neu += 1\n",
    "            else:\n",
    "                 pass\n",
    "        if pos == 0 and neg == 0:\n",
    "            quar_point.append(0)\n",
    "        else:\n",
    "            art_point = (pos-neg)/(pos+neg)\n",
    "            quar_point.append(art_point)\n",
    "    point.append(quar_point)\n",
    "    \n",
    "mean_point_현대중공업 = []\n",
    "\n",
    "for i in point:\n",
    "    if len(i) == 0:\n",
    "        mean_point_현대중공업.append(0)\n",
    "    else:\n",
    "        mean_point_현대중공업.append(sum(i, 0.0)/len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한국전력 분기의 마지막 10기사의 점수\n",
    "point = []\n",
    "\n",
    "for i in data_한국전력: #한개의 분기\n",
    "    quar_point = []\n",
    "    reverse = i[::-1][:9]\n",
    "    for j in reverse:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        neu = 0\n",
    "        for k in j:\n",
    "            if k in sentiment_dict['positive']:\n",
    "                pos += 1\n",
    "            elif k in sentiment_dict['negative']:\n",
    "                neg += 1\n",
    "            elif k in sentiment_dict['neutral']:\n",
    "                neu += 1\n",
    "            else:\n",
    "                 pass\n",
    "        if pos == 0 and neg == 0:\n",
    "            quar_point.append(0)\n",
    "        else:\n",
    "            art_point = (pos-neg)/(pos+neg)\n",
    "            quar_point.append(art_point)\n",
    "    point.append(quar_point)\n",
    "    \n",
    "mean_point_한국전력 = []\n",
    "\n",
    "for i in point:\n",
    "    if len(i) == 0:\n",
    "        mean_point_한국전력.append(0)\n",
    "    else:\n",
    "        mean_point_한국전력.append(sum(i, 0.0)/len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LG디스플레이 분기의 마지막 10기사의 점수\n",
    "point = []\n",
    "\n",
    "for i in data_LG디스플레이: #한개의 분기\n",
    "    quar_point = []\n",
    "    reverse = i[::-1][:9]\n",
    "    for j in reverse:\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        neu = 0\n",
    "        for k in j:\n",
    "            if k in sentiment_dict['positive']:\n",
    "                pos += 1\n",
    "            elif k in sentiment_dict['negative']:\n",
    "                neg += 1\n",
    "            elif k in sentiment_dict['neutral']:\n",
    "                neu += 1\n",
    "            else:\n",
    "                 pass\n",
    "        if pos == 0 and neg == 0:\n",
    "            quar_point.append(0)\n",
    "        else:\n",
    "            art_point = (pos-neg)/(pos+neg)\n",
    "            quar_point.append(art_point)\n",
    "    point.append(quar_point)\n",
    "    \n",
    "mean_point_LG디스플레이 = []\n",
    "\n",
    "for i in point:\n",
    "    if len(i) == 0:\n",
    "        mean_point_LG디스플레이.append(0)\n",
    "    else:\n",
    "        mean_point_LG디스플레이.append(sum(i, 0.0)/len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사업보고서 감성점수 불러오기\n",
    "my_path = 'C:/Users/rjsfu/Dropbox/task/텍스트마이닝/관련 자료'\n",
    "\n",
    "with open(my_path + '/' + 'report_sentiscore' +'.csv', 'r', encoding = 'utf-8') as f:\n",
    "    doc = f.read()\n",
    "    report_sent = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5311dbd0cc05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreport_sent_한국전력\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mreport_score_한국전력\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "report_sent_LG디스플레이 = report_sent[1:41]\n",
    "report_sent_현대차 = report_sent[41:81]\n",
    "report_sent_현대중공업 = report_sent[81:121]\n",
    "report_sent_한국전력 = report_sent[121:]\n",
    "\n",
    "report_score_현대차 = []\n",
    "for i in report_sent_현대차:\n",
    "    temp = i.split(',')\n",
    "    report_score_현대차.append(temp[5])\n",
    "    \n",
    "report_score_현대중공업 = []\n",
    "for i in report_sent_현대중공업:\n",
    "    temp = i.split(',')\n",
    "    report_score_현대중공업.append(temp[5])\n",
    "    \n",
    "report_score_LG디스플레이 = []\n",
    "for i in report_sent_LG디스플레이:\n",
    "    temp = i.split(',')\n",
    "    report_score_LG디스플레이.append(temp[5])\n",
    "\n",
    "\n",
    "report_score_한국전력 = []\n",
    "for i in report_sent_한국전력:\n",
    "    temp = i.split(',')\n",
    "    report_score_한국전력.append(temp[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주가의 up& down 불러오기\n",
    "my_path = 'C:/Users/rjsfu/Dropbox/task/텍스트마이닝/관련 자료'\n",
    "\n",
    "#######한국전력###########\n",
    "with open(my_path + '/' + '한국전력 up&down' +'.csv', 'r', encoding = 'utf-8') as f:\n",
    "    doc = f.read()\n",
    "    한국전력_up_down = doc.split('\\n')\n",
    "\n",
    "한국전력_ud = []\n",
    "for i in 한국전력_up_down:\n",
    "    temp = i.split(',')\n",
    "    한국전력_ud.append(temp[1])\n",
    "    \n",
    "for i in range(len(한국전력_ud)):\n",
    "    if 한국전력_ud[i] == '2':\n",
    "        한국전력_ud[i] = 0\n",
    "    elif 한국전력_ud[i] == '1':\n",
    "        한국전력_ud[i] = 1\n",
    "    else:\n",
    "        한국전력_ud[i] = 0 \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "######현대중공업##########    \n",
    "with open(my_path + '/' + '현대중공업 up&down' +'.csv', 'r', encoding = 'utf-8') as f:\n",
    "    doc = f.read()\n",
    "    현대중공업_up_down = doc.split('\\n')\n",
    "    \n",
    "현대중공업_ud = []\n",
    "for i in 현대중공업_up_down:\n",
    "    temp = i.split(',')\n",
    "    현대중공업_ud.append(temp[1])\n",
    "    \n",
    "for i in range(len(현대중공업_ud)):\n",
    "    if 현대중공업_ud[i] == '2':\n",
    "        현대중공업_ud[i] = 0\n",
    "    elif 현대중공업_ud[i] == '1':\n",
    "        현대중공업_ud[i] = 1\n",
    "    else:\n",
    "        현대중공업_ud[i] = 0 \n",
    "    \n",
    "    \n",
    "#######현대차##########\n",
    "with open(my_path + '/' + '현대차 up&down' +'.csv', 'r', encoding = 'utf-8') as f:\n",
    "    doc = f.read()\n",
    "    현대차_up_down = doc.split('\\n')\n",
    "    \n",
    "현대차_ud = []\n",
    "for i in 현대차_up_down:\n",
    "    temp = i.split(',')\n",
    "    현대차_ud.append(temp[1])\n",
    "\n",
    "for i in range(len(현대차_ud)):\n",
    "    if 현대차_ud[i] == '2':\n",
    "        현대차_ud[i] = 0\n",
    "    elif 현대차_ud[i] == '1':\n",
    "        현대차_ud[i] = 1\n",
    "    else:\n",
    "        현대차_ud[i] = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "########LG디스플레이########\n",
    "with open(my_path + '/' + 'LG디스플레이 up&down' +'.csv', 'r', encoding = 'utf-8') as f:\n",
    "    doc = f.read()\n",
    "    LG디스플레이_up_down = doc.split('\\n')\n",
    "    \n",
    "LG디스플레이_ud = []\n",
    "for i in LG디스플레이_up_down:\n",
    "    temp = i.split(',')\n",
    "    LG디스플레이_ud.append(temp[1])\n",
    "    \n",
    "for i in range(len(LG디스플레이_ud)):\n",
    "    if LG디스플레이_ud[i] == '2':\n",
    "        LG디스플레이_ud[i] = 0\n",
    "    elif LG디스플레이_ud[i] == '1':\n",
    "        LG디스플레이_ud[i] = 1\n",
    "    else:\n",
    "        LG디스플레이_ud[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#현대차 정확도\n",
    "final_score_현대차 = []\n",
    "for i in range(len(report_score_현대차)):\n",
    "    score = (0.7*mean_point_현대차[i]) + (0.3*float(report_score_현대차[i]))\n",
    "    final_score_현대차.append(score)\n",
    "    \n",
    "score_ud_현대차 = []\n",
    "for i in final_score_현대차:\n",
    "    if i > 0.25:\n",
    "        score_ud_현대차.append(1)\n",
    "    else:\n",
    "        score_ud_현대차.append(0)\n",
    "        \n",
    "acc_현대차 = np.mean(np.equal(np.array(score_ud_현대차), np.array(현대차_ud)))\n",
    "acc_현대차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LG디스플레이 정확도\n",
    "final_score_LG디스플레이 = []\n",
    "for i in range(len(report_score_LG디스플레이)):\n",
    "    score = (0.7*mean_point_LG디스플레이[i]) + (0.3*float(report_score_LG디스플레이[i]))\n",
    "    final_score_LG디스플레이.append(score)\n",
    "    \n",
    "score_ud_LG디스플레이 = []\n",
    "for i in final_score_LG디스플레이:\n",
    "    if i > 0.45:\n",
    "        score_ud_LG디스플레이.append(1)\n",
    "    else:\n",
    "        score_ud_LG디스플레이.append(0)\n",
    "        \n",
    "acc_LG디스플레이 = np.mean(np.equal(np.array(score_ud_LG디스플레이), np.array(LG디스플레이_ud)))\n",
    "acc_LG디스플레이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#현대중공업 정확도\n",
    "final_score_현대중공업 = []\n",
    "for i in range(len(report_score_현대중공업)):\n",
    "    score = (0.7*mean_point_현대중공업[i]) + (0.3*float(report_score_현대중공업[i]))\n",
    "    final_score_현대중공업.append(score)\n",
    "    \n",
    "score_ud_현대중공업 = []\n",
    "for i in final_score_현대중공업:\n",
    "    if i > 0.22:\n",
    "        score_ud_현대중공업.append(1)\n",
    "    else:\n",
    "        score_ud_현대중공업.append(0)\n",
    "        \n",
    "acc_현대중공업 = np.mean(np.equal(np.array(score_ud_현대중공업), np.array(현대중공업_ud)))\n",
    "acc_현대중공업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#한국전력 정확도\n",
    "final_score_한국전력 = []\n",
    "for i in range(len(report_score_한국전력)):\n",
    "    score = (0.7*mean_point_한국전력[i]) + (0.3*float(report_score_한국전력[i]))\n",
    "    final_score_한국전력.append(score)\n",
    "    \n",
    "score_ud_한국전력 = []\n",
    "for i in final_score_한국전력:\n",
    "    if i > 0.45:\n",
    "        score_ud_한국전력.append(1)\n",
    "    else:\n",
    "        score_ud_한국전력.append(0)\n",
    "        \n",
    "acc_한국전력 = np.mean(np.equal(np.array(score_ud_한국전력), np.array(한국전력_ud)))\n",
    "acc_한국전력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
